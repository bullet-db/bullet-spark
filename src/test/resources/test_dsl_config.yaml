# Point to the Mock PubSub implementation.
bullet.pubsub.class.name: "com.yahoo.bullet.spark.MockPubSub"
# This is the type of PubSub context to use
bullet.pubsub.context.name: "QUERY_PROCESSING"

bullet.spark.data.producer.class.name: "com.yahoo.bullet.spark.MockDataProducer"
bullet.spark.loop.pubsub.overrides:
  "name": "fake"

bullet.spark.batch.duration.ms: 1000
bullet.spark.data.producer.parallelism: 1
spark.default.parallelism": "1"
spark.streaming.blockInterval": "1ms"
spark.streaming.receiverRestartDelay": "1"
bullet.spark.metrics.enabled: false
bullet.spark.checkpoint.dir: "target/spark-test"
bullet.spark.query.union.checkpoint.duration.multiplier: 10
bullet.spark.join.checkpoint.duration.multiplier: 10

bullet.dsl.converter.class.name: "com.yahoo.bullet.dsl.converter.MapBulletRecordConverter"

bullet.dsl.connector.class.name: "com.yahoo.bullet.spark.MockConnector"
#bullet.dsl.connector.class.name: "com.yahoo.bullet.dsl.connector.KafkaConnector"
bullet.dsl.connector.read.timeout.ms: 0
bullet.dsl.connector.async.commit.enable: true
bullet.dsl.connector.kafka.start.at.end.enable: true
bullet.dsl.connector.kafka.topics:
- "poe.stash"
bullet.dsl.connector.kafka.bootstrap.servers: "localhost:9092"
bullet.dsl.connector.kafka.group.id: "mygroup"
bullet.dsl.connector.kafka.key.deserializer: "org.apache.kafka.common.serialization.StringDeserializer"
bullet.dsl.connector.kafka.value.deserializer: "org.apache.kafka.common.serialization.ByteArrayDeserializer"

bullet.dsl.deserializer.class.name: "com.yahoo.bullet.dsl.deserializer.IdentityDeserializer"
#bullet.dsl.deserializer.class.name: "com.yahoo.bullet.dsl.deserializer.JavaDeserializer"